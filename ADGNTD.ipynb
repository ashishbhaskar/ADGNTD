{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d618f3-fe60-4e2c-a68a-e0bf86ef04df",
   "metadata": {},
   "source": [
    "1. Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5b252b-b734-41f0-92cc-bb462fda2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from collections import deque\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import bmat, coo_matrix, csr_matrix, diags, kron, load_npz\n",
    "from scipy import linalg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.constraints import NonNeg\n",
    "from tensorflow.keras.layers import Bidirectional, Dense, LSTM, TimeDistributed, Flatten, Reshape\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tabulate import tabulate\n",
    "from itertools import chain\n",
    "from termcolor import colored\n",
    "from random import randrange\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import cupy as cp\n",
    "import time\n",
    "import traceback\n",
    "import datetime\n",
    "import math\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb1be2-fada-4531-9253-dadd40a63374",
   "metadata": {},
   "source": [
    "2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42bb5b7-25cc-406b-a1a9-5bcdaa82f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy is using the GPU.\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.random.rand(100)\n",
    "cupy_array = cp.asarray(numpy_array)\n",
    "if cupy_array.data.device.id >= 0:\n",
    "    print(\"CuPy is using the GPU.\")\n",
    "else:\n",
    "    print(\"CuPy is NOT using the GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c481e9-f7d1-444b-a57d-aeaa8f496648",
   "metadata": {},
   "source": [
    "3. Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8266941f-43b5-45db-93e7-a71cdc6bbe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. folding and Unfolding a 3D tensor\n",
    "def unfolding_3D(Tens, unfol_dim, other_dim_seq ):\n",
    "    X = Tens.transpose(unfol_dim, other_dim_seq[0], other_dim_seq[1]).reshape(Tens.shape[unfol_dim], Tens.shape[other_dim_seq[0]] * Tens.shape[other_dim_seq[1]])\n",
    "    return (X)\n",
    "def folding_3D(Unfold_Tens, unfol_dim , other_dim_seq, Tens_shape):\n",
    "    a = [0,1,2]\n",
    "    items = deque(a)\n",
    "    items.rotate(unfol_dim) \n",
    "    a_up= list(items)\n",
    "    X = Unfold_Tens.reshape(Tens_shape[unfol_dim], Tens_shape[other_dim_seq[0]],Tens_shape[other_dim_seq[1]]).transpose(a_up[0], a_up[1], a_up[2])    \n",
    "    return (X)\n",
    "#2. ADGNTD functions\n",
    "def derivative_dynamic_graph_A_W(A, B, W):\n",
    "    In = csr_matrix(np.identity(A.shape[1]))\n",
    "    Ip = csr_matrix(np.identity(B.shape[0]))\n",
    "    Imn = csr_matrix(np.identity(A.shape[0] * A.shape[1]))\n",
    "    ones = csr_matrix(np.ones((1, A.shape[0])))\n",
    "    Eta_rep = csr_matrix(linalg.khatri_rao(Imn.toarray(), (B.dot(kron(In, ones))).toarray()))\n",
    "    Eta = Eta_rep.T.dot(kron(In.T, W)).dot(Eta_rep)\n",
    "    derivative_A = (Eta + Eta.T).dot(vect(A))\n",
    "    derivative_A_mat = vec_to_Mat(derivative_A, A.shape)\n",
    "    return(csr_matrix(derivative_A_mat))\n",
    "def derivative_dynamic_graph_A_D(A, B, Deg):\n",
    "    In = csr_matrix(np.identity(A.shape[1]))\n",
    "    Ip = csr_matrix(np.identity(B.shape[0]))\n",
    "    Imn = csr_matrix(np.identity(A.shape[0] * A.shape[1]))\n",
    "    ones = csr_matrix(np.ones((1, A.shape[0])))\n",
    "    Eta_rep = csr_matrix(linalg.khatri_rao(Imn.toarray(), (B.dot(kron(In, ones))).toarray()))\n",
    "    Eta = Eta_rep.T.dot(kron(In.T, Deg)).dot(Eta_rep)\n",
    "    derivative_A = (Eta + Eta.T).dot(vect(A))\n",
    "    derivative_A_mat = vec_to_Mat(derivative_A, A.shape)\n",
    "    return(csr_matrix(derivative_A_mat))\n",
    "def derivative_dynamic_graph_B_W(A, B, W):\n",
    "    In = csr_matrix(np.identity(A.shape[1]))\n",
    "    Ip = csr_matrix(np.identity(B.shape[0]))\n",
    "    I_dash = diags(np.ones((W.shape[0],)))\n",
    "    Xi_rep = kron(linalg.khatri_rao(In.toarray(), A.toarray()), Ip)\n",
    "    Xi = Xi_rep.T.dot(kron(In.T , W)).dot(Xi_rep)\n",
    "    derivative_B = (Xi + Xi.T).dot(vect(B))\n",
    "    derivative_B_mat = vec_to_Mat(derivative_B, B.shape)\n",
    "    return(csr_matrix(derivative_B_mat))\n",
    "def derivative_dynamic_graph_B_D(A, B, Deg):\n",
    "    In = csr_matrix(np.identity(A.shape[1]))\n",
    "    Ip = csr_matrix(np.identity(B.shape[0]))\n",
    "    Xi_rep = kron(linalg.khatri_rao(In.toarray(), A.toarray()), Ip)\n",
    "    Xi = Xi_rep.T.dot(kron(In.T , Deg)).dot(Xi_rep)\n",
    "    derivative_B = (Xi + Xi.T).dot(vect(B))\n",
    "    derivative_B_mat = vec_to_Mat(derivative_B, B.shape)\n",
    "    return(csr_matrix(derivative_B_mat))\n",
    "def vect(Mat):\n",
    "    x = Mat.shape[0]\n",
    "    y = Mat.shape[1]\n",
    "    vec_A = Mat.T.reshape(x*y,1)\n",
    "    return(vec_A)\n",
    "def vec_to_Mat(vec, shape):\n",
    "    x = shape[0]\n",
    "    y = shape[1]\n",
    "    Mat = vec.reshape(y,x).T\n",
    "    return (Mat)\n",
    "def rmse(a, b):\n",
    "    rms = np.sqrt(np.power(a-b, 2).sum()/(a.shape[0]* a.shape[1]))\n",
    "    return (round(rms,2))\n",
    "    \n",
    "def calculate_smoothed_weights(mat):\n",
    "    identity_matrix = np.identity(mat.shape[0])\n",
    "    W_smooth = -pd.DataFrame(identity_matrix).rolling(2, axis=1).sum().replace(np.nan, 0)\n",
    "    W_smooth[0] = -pd.DataFrame(identity_matrix)[0]\n",
    "    W_smooth = np.array(W_smooth + 2 * pd.DataFrame(identity_matrix))\n",
    "    W_smooth_pos = (np.abs(W_smooth) + W_smooth) / 2\n",
    "    W_smooth_neg = (np.abs(W_smooth) - W_smooth) / 2\n",
    "    neum_term_B = csr_matrix(W_smooth_neg.T.dot(W_smooth_neg))\n",
    "    denom_term_B = csr_matrix(W_smooth_pos.T.dot(W_smooth_pos))\n",
    "    return  (neum_term_B, denom_term_B)\n",
    "\n",
    "def calculate_smoothed_weights_cp(mat):\n",
    "    identity_matrix = np.identity(mat.shape[0])\n",
    "    W_smooth = -pd.DataFrame(identity_matrix).rolling(2, axis=1).sum().replace(np.nan, 0)\n",
    "    W_smooth[0] = -pd.DataFrame(identity_matrix)[0]\n",
    "    W_smooth = np.array(W_smooth + 2 * pd.DataFrame(identity_matrix))\n",
    "    W_smooth_pos = (np.abs(W_smooth) + W_smooth) / 2\n",
    "    W_smooth_neg = (np.abs(W_smooth) - W_smooth) / 2\n",
    "    neum_term_B = cp.asarray(W_smooth_neg.T.dot(W_smooth_neg))\n",
    "    denom_term_B = cp.asarray(W_smooth_pos.T.dot(W_smooth_pos))\n",
    "    return  (neum_term_B, denom_term_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90092eb-c10f-43d9-9b51-55bc3db79b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADGNTD(Tens1, W_prior, r = 10, n_iter=100, hy1=1, hy2=1, mu=0.1, factorization1=1000,\n",
    "                      prin=50, A = None, B = None, C = None, W = None, delta = None ):\n",
    "    T3 = csr_matrix(unfolding_3D(Tens1, unfol_dim = 2, other_dim_seq = [0,1] ))\n",
    "    plot = []\n",
    "    try:\n",
    "        if (A == None) | (B == None)|  (C == None):\n",
    "            A = csr_matrix(np.random.rand(Tens1.shape[0],r))\n",
    "            B = csr_matrix(np.random.rand(Tens1.shape[1],r))\n",
    "            C = csr_matrix(np.random.rand(Tens1.shape[2],r))\n",
    "        if (W == None):\n",
    "            W = W_prior.copy()\n",
    "            delta = W*.5\n",
    "        if (delta == None):\n",
    "            delta = W*.5\n",
    "        A_list = list(range(A.shape[0]))\n",
    "        B_list = list(range(B.shape[0]))\n",
    "        C_list = list(range(C.shape[0]))\n",
    "        neum_term_B, denom_term_B = calculate_smoothed_weights(B)\n",
    "        for indomie in range(n_iter):\n",
    "            A_Batch = Tens1.shape[0] // 1\n",
    "            B_Batch = Tens1.shape[1] // 1\n",
    "            C_Batch = Tens1.shape[2] // 1\n",
    "            A_int = random.randrange(A.shape[0])\n",
    "            B_int = random.randrange(B.shape[0])\n",
    "            C_int = random.randrange(C.shape[0])\n",
    "            A_Sampling = random.sample(A_list, A_Batch)\n",
    "            B_Sampling = random.sample(B_list, B_Batch)\n",
    "            C_Sampling = random.sample(C_list, C_Batch)\n",
    "            A_Sampled = csr_matrix(A[A_Sampling, :])\n",
    "            B_Sampled = csr_matrix(B[B_Sampling, :])\n",
    "            C_Sampled = csr_matrix(C[C_Sampling, :])\n",
    "            Tens_sample = Tens1[A_Sampling, :, :][:, B_Sampling, :][:, :, C_Sampling]\n",
    "            T1_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=0, other_dim_seq=[1, 2]))\n",
    "            T2_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=1, other_dim_seq=[2, 0]))\n",
    "            T3_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=2, other_dim_seq=[0, 1]))\n",
    "            # Loop through B_Sampling indices and create w_list_B\n",
    "            for index, j in enumerate(B_Sampling):\n",
    "                if index == 0:\n",
    "                    w_list_B = list(range(j * A.shape[0], (j + 1) * A.shape[0]))\n",
    "                if index > 0:\n",
    "                    w_list_B += list(range(j * A.shape[0], (j + 1) * A.shape[0]))\n",
    "            \n",
    "            # Loop through B indices and create w_list_A\n",
    "            for i in range(0, B.shape[0]):\n",
    "                if i == 0:\n",
    "                    w_list_A = list(np.array(A_Sampling) + i * A.shape[0])\n",
    "                if i > 0:\n",
    "                    w_list_A += list(np.array(A_Sampling) + i * A.shape[0])\n",
    "            \n",
    "            # Find common indices between w_list_A and w_list_B\n",
    "            w_list = list(set(w_list_A) & set(w_list_B))\n",
    "            # Sample submatrix W_sampled from W using w_list indices\n",
    "            W_sampled = W[w_list, :][:, w_list]\n",
    "            # Calculate degree matrix for sampled nodes\n",
    "            Deg_sampled = sparse.diags(np.squeeze(np.asarray(W_sampled.sum(axis=0)))).tocsr()\n",
    "            # Sample submatrix W_prior_sampled from W_prior using w_list indices\n",
    "            W_prior_sampled = W_prior[w_list, :][:, w_list]\n",
    "            # Sample submatrix delta_sampled from delta using w_list indices\n",
    "            delta_sampled = delta[w_list, :][:, w_list]\n",
    "            # Create matrix V using Khatri-Rao product of B_Sampled and C_Sampled\n",
    "            V = csr_matrix(linalg.khatri_rao(B_Sampled.toarray(), C_Sampled.toarray()))\n",
    "            # Update A_Sampled using optimization step\n",
    "            A_Sampled = csr_matrix(A_Sampled.multiply(T1_sampled.dot(V) \n",
    "                                                      + hy1 * derivative_dynamic_graph_A_W(A_Sampled, B_Sampled, W_sampled)) / \n",
    "                                   (A_Sampled.dot(V.T).dot(V) + hy2 * A_Sampled + \n",
    "                                    hy1 * derivative_dynamic_graph_A_D(A_Sampled, B_Sampled, Deg_sampled)))\n",
    "            # Update rows of A using A_Sampling indices\n",
    "            A[A_Sampling, :] = A_Sampled\n",
    "            # Recalculate matrix V using Khatri-Rao product of C_Sampled and A_Sampled\n",
    "            V = csr_matrix(linalg.khatri_rao(C_Sampled.toarray(), A_Sampled.toarray()))\n",
    "            # Update B_Sampled using optimization step\n",
    "            B_num = B_Sampled.multiply(csr_matrix(T2_sampled.dot(V)) + 5 * (neum_term_B.dot(B)) \n",
    "                                       + hy1 * derivative_dynamic_graph_B_W(A_Sampled, B_Sampled, W_sampled))\n",
    "            B_denom = (B_Sampled.dot(V.T).dot(V) + hy2 * B_Sampled + 5 * (denom_term_B.dot(B)) \n",
    "                       + hy1 * derivative_dynamic_graph_B_D(A_Sampled, B_Sampled, Deg_sampled))\n",
    "            B_Sampled = csr_matrix(B_num / B_denom)\n",
    "            # Update rows of B using B_Sampling indices\n",
    "            B[B_Sampling, :] = B_Sampled\n",
    "            # Recalculate matrix V using Khatri-Rao product of A_Sampled and B_Sampled\n",
    "            V = csr_matrix(linalg.khatri_rao(A_Sampled.toarray(), B_Sampled.toarray()))\n",
    "            # Update C_Sampled using optimization step\n",
    "            C_Sampled = csr_matrix(C_Sampled.multiply(T3_sampled.dot(V)) / (C_Sampled.dot(V.T).dot(V) + hy2 * C_Sampled))\n",
    "            # Update rows of C using C_Sampling indices\n",
    "            C[C_Sampling, :] = C_Sampled\n",
    "            # Estimate matrix EstimatedT4 using calculated matrices\n",
    "            EstimatedT4 = C.todense().dot(linalg.khatri_rao(A.todense(), B.todense()).T)\n",
    "            # Update delta_sampled with mu term\n",
    "            delta_sampled = delta_sampled + mu * (delta_sampled.T - delta_sampled)\n",
    "            # Update submatrix delta using delta_sampled and w_list indices\n",
    "            delta[w_list, :][:, w_list] = delta_sampled\n",
    "            if indomie%prin == 0:\n",
    "                try:\n",
    "                    factorization1 =  min(factorization, factorization1)\n",
    "                except:\n",
    "                    pass\n",
    "                factorization = rmse(T3, EstimatedT4).round(2)\n",
    "                plot.append([indomie, factorization])\n",
    "                abcd = pd.DataFrame(plot, columns = ['iteration', 'RMSE'])\n",
    "            if indomie%prin == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(\".............................................\")\n",
    "                print('iteration:                       ',indomie)\n",
    "                print('rmse factorization :             ', factorization )\n",
    "                try:\n",
    "                    print('rmse factorization min:          ', min(factorization, factorization1))\n",
    "                except:\n",
    "                    pass\n",
    "                print('.............................................')\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard interruption detected. Returning...\")\n",
    "        return(A, B, C, W, delta)\n",
    "    return(A, B, C, W, delta)\n",
    "\n",
    "def ADGNTD_stochastic(Tens1, W_prior, r = 10, iter_steps = [1000, 2000, 3000],\n",
    "                      batchsize = [[20, 100, 20], [40,100,40], [60,100,60]], \n",
    "                      hy1=1, hy2=1, mu=0.1, factorization1=1000, max_iter = 6000,\n",
    "                      prin=50, A = None, B = None, C = None, W = None, delta = None ):\n",
    "    Tens1 = cp.asarray(Tens1)\n",
    "    W_prior = cp.asarray(W_prior)\n",
    "    def unfolding_3D(Tens, unfol_dim, other_dim_seq):\n",
    "        # Convert the input tensor to CuPy\n",
    "        \n",
    "        # Transpose the tensor using CuPy's transpose\n",
    "        X = cp.transpose(Tens_cp, (unfol_dim, other_dim_seq[0], other_dim_seq[1]))\n",
    "        # Reshape the tensor using CuPy's reshape\n",
    "        X = cp.reshape(X, (X.shape[unfol_dim], X.shape[other_dim_seq[0]] * X.shape[other_dim_seq[1]]))\n",
    "        return X\n",
    "\n",
    "    T3 = csr_matrix(unfolding_3D(Tens1, unfol_dim = 2, other_dim_seq = [0,1] ))\n",
    "    plot = []\n",
    "    try:\n",
    "        if (A == None) | (B == None)|  (C == None):\n",
    "            A = csr_matrix(np.random.rand(Tens1.shape[0],r))\n",
    "            B = csr_matrix(np.random.rand(Tens1.shape[1],r))\n",
    "            C = csr_matrix(np.random.rand(Tens1.shape[2],r))\n",
    "        if (W == None):\n",
    "            W = W_prior.copy()\n",
    "            delta = W*.5\n",
    "        if (delta == None):\n",
    "            delta = W*.5\n",
    "        A_list = list(range(A.shape[0]))\n",
    "        B_list = list(range(B.shape[0]))\n",
    "        C_list = list(range(C.shape[0]))\n",
    "        neum_term_B, denom_term_B = calculate_smoothed_weights(B)\n",
    "        start = 0\n",
    "        for indomie in range(max_iter):\n",
    "            try:\n",
    "                change_iter = iter_steps[start]\n",
    "            except:\n",
    "                change_iter = 100000000\n",
    "            if indomie >= change_iter:\n",
    "                start = start+1\n",
    "                #print('yes')\n",
    "            if indomie <= change_iter:\n",
    "                try:\n",
    "                    batchsize_selected = batchsize [start]\n",
    "                except:\n",
    "                    pass\n",
    "            #print(batchsize_selected)\n",
    "            A_Batch = int(batchsize_selected[0] / 100 * Tens1.shape[0] )\n",
    "            B_Batch = Tens1.shape[1]\n",
    "            C_Batch = int(batchsize_selected[2] / 100 * Tens1.shape[2] )\n",
    "            A_int = random.randrange(A.shape[0])\n",
    "            B_int = random.randrange(B.shape[0])\n",
    "            C_int = random.randrange(C.shape[0])\n",
    "            A_Sampling = random.sample(A_list, A_Batch)\n",
    "            B_Sampling = random.sample(B_list, B_Batch)\n",
    "            C_Sampling = random.sample(C_list, C_Batch)\n",
    "            A_Sampled = csr_matrix(A[A_Sampling, :])\n",
    "            B_Sampled = csr_matrix(B[B_Sampling, :])\n",
    "            C_Sampled = csr_matrix(C[C_Sampling, :])\n",
    "            Tens_sample = Tens1[A_Sampling, :, :][:, B_Sampling, :][:, :, C_Sampling]\n",
    "            T1_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=0, other_dim_seq=[1, 2]))\n",
    "            T2_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=1, other_dim_seq=[2, 0]))\n",
    "            T3_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=2, other_dim_seq=[0, 1]))\n",
    "            # Loop through B_Sampling indices and create w_list_B\n",
    "            for index, j in enumerate(B_Sampling):\n",
    "                if index == 0:\n",
    "                    w_list_B = list(range(j * A.shape[0], (j + 1) * A.shape[0]))\n",
    "                if index > 0:\n",
    "                    w_list_B += list(range(j * A.shape[0], (j + 1) * A.shape[0]))\n",
    "            \n",
    "            # Loop through B indices and create w_list_A\n",
    "            for i in range(0, B.shape[0]):\n",
    "                if i == 0:\n",
    "                    w_list_A = list(np.array(A_Sampling) + i * A.shape[0])\n",
    "                if i > 0:\n",
    "                    w_list_A += list(np.array(A_Sampling) + i * A.shape[0])\n",
    "            \n",
    "            # Find common indices between w_list_A and w_list_B\n",
    "            w_list = list(set(w_list_A) & set(w_list_B))\n",
    "            # Sample submatrix W_sampled from W using w_list indices\n",
    "            W_sampled = W[w_list, :][:, w_list]\n",
    "            # Calculate degree matrix for sampled nodes\n",
    "            Deg_sampled = sparse.diags(np.squeeze(np.asarray(W_sampled.sum(axis=0)))).tocsr()\n",
    "            # Sample submatrix W_prior_sampled from W_prior using w_list indices\n",
    "            W_prior_sampled = W_prior[w_list, :][:, w_list]\n",
    "            # Sample submatrix delta_sampled from delta using w_list indices\n",
    "            delta_sampled = delta[w_list, :][:, w_list]\n",
    "            # Create matrix V using Khatri-Rao product of B_Sampled and C_Sampled\n",
    "            V = csr_matrix(linalg.khatri_rao(B_Sampled.toarray(), C_Sampled.toarray()))\n",
    "            # Update A_Sampled using optimization step\n",
    "            A_Sampled = csr_matrix(A_Sampled.multiply(T1_sampled.dot(V) \n",
    "                                                      + hy1 * derivative_dynamic_graph_A_W(A_Sampled, B_Sampled, W_sampled)) / \n",
    "                                   (A_Sampled.dot(V.T).dot(V) + hy2 * A_Sampled + \n",
    "                                    hy1 * derivative_dynamic_graph_A_D(A_Sampled, B_Sampled, Deg_sampled)))\n",
    "            # Update rows of A using A_Sampling indices\n",
    "            A[A_Sampling, :] = A_Sampled\n",
    "            # Recalculate matrix V using Khatri-Rao product of C_Sampled and A_Sampled\n",
    "            V = csr_matrix(linalg.khatri_rao(C_Sampled.toarray(), A_Sampled.toarray()))\n",
    "            # Update B_Sampled using optimization step\n",
    "            B_num = B_Sampled.multiply(csr_matrix(T2_sampled.dot(V)) + 5 * (neum_term_B.dot(B)) \n",
    "                                       + hy1 * derivative_dynamic_graph_B_W(A_Sampled, B_Sampled, W_sampled))\n",
    "            B_denom = (B_Sampled.dot(V.T).dot(V) + hy2 * B_Sampled + 5 * (denom_term_B.dot(B)) \n",
    "                       + hy1 * derivative_dynamic_graph_B_D(A_Sampled, B_Sampled, Deg_sampled))\n",
    "            B_Sampled = csr_matrix(B_num / B_denom)\n",
    "            # Update rows of B using B_Sampling indices\n",
    "            B[B_Sampling, :] = B_Sampled\n",
    "            # Recalculate matrix V using Khatri-Rao product of A_Sampled and B_Sampled\n",
    "            V = csr_matrix(linalg.khatri_rao(A_Sampled.toarray(), B_Sampled.toarray()))\n",
    "            # Update C_Sampled using optimization step\n",
    "            C_Sampled = csr_matrix(C_Sampled.multiply(T3_sampled.dot(V)) / (C_Sampled.dot(V.T).dot(V) + hy2 * C_Sampled))\n",
    "            # Update rows of C using C_Sampling indices\n",
    "            C[C_Sampling, :] = C_Sampled\n",
    "            # Estimate matrix EstimatedT4 using calculated matrices\n",
    "            EstimatedT4 = C.todense().dot(linalg.khatri_rao(A.todense(), B.todense()).T)\n",
    "            # Update delta_sampled with mu term\n",
    "            \n",
    "            feature_Matrix = csr_matrix(linalg.khatri_rao(A_Sampled.toarray(), B_Sampled.toarray()))\n",
    "            #print((Lambda_priorW * W_prior).shape)\n",
    "            #print((Lambda_adaptive * .5* feature_Matrix.dot(feature_Matrix.T)).shape) \n",
    "            #print(Lambda_priorW * W_prior + Lambda_adaptive * .5* feature_Matrix.dot(feature_Matrix.T)) \n",
    "            Deg1, W1 = adaptive_Adjacency_aug(W_sampled, W_prior_sampled, feature_Matrix, mu, delta_sampled, Lambda_adaptive, Lambda_priorW , epsilon )\n",
    "            #print(C.shape, A.shape, B.shape)\n",
    "            W[w_list, :][:, w_list] = W1\n",
    "            Deg = sparse.diags(np.squeeze(np.asarray(W.sum(axis = 0)))).tocsr()\n",
    "            if indomie%prin == 0:\n",
    "                try:\n",
    "                    factorization1 =  min(factorization, factorization1)\n",
    "                except:\n",
    "                    pass\n",
    "                factorization = rmse(T3, EstimatedT4).round(2)\n",
    "                plot.append([indomie, factorization])\n",
    "                abcd = pd.DataFrame(plot, columns = ['iteration', 'RMSE'])\n",
    "            if indomie%prin == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(\".............................................\")\n",
    "                print('iteration:                       ',indomie)\n",
    "                print('rmse factorization :             ', factorization )\n",
    "                try:\n",
    "                    print('rmse factorization min:          ', min(factorization, factorization1))\n",
    "                    print('batchsize_selected:          ', batchsize_selected)\n",
    "                    #batchsize_selected\n",
    "                except:\n",
    "                    pass\n",
    "                print('.............................................')\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard interruption detected. Returning...\")\n",
    "        return(A, B, C, W, delta)\n",
    "        \n",
    "    return(A, B, C, W, delta)\n",
    "def adaptive_Adjacency_aug(W, W_prior, feature_Matrix, mu, delta, Lambda_adaptive, Lambda_priorW , epsilon ):\n",
    "    neum = csr_matrix(Lambda_priorW * W_prior + Lambda_adaptive * .5* feature_Matrix.dot(feature_Matrix.T)) #OK \n",
    "    One_n = csr_matrix(np.ones(W.shape[0]).reshape(W.shape[0], 1))\n",
    "    Identity_r = csr_matrix(np.identity(feature_Matrix.shape[1]))\n",
    "    Identity_n = csr_matrix(np.identity(W.shape[0]))\n",
    "    Third_term = csr_matrix((feature_Matrix.dot(Identity_r).dot(feature_Matrix.T).multiply(Identity_n) ).dot(One_n).dot(One_n.T)) \n",
    "    denom =  Lambda_adaptive * .5* Third_term + Lambda_priorW * W #+ .5* np.identity(W.shape[0]) \n",
    "    temp = mu * (W-W.T) + delta - delta.T\n",
    "    temp_pos = (abs(temp) + temp)/2\n",
    "    temp_neg = (abs(temp) - temp)/2\n",
    "    W = W.multiply(csr_matrix((neum  + temp_neg).todense() + epsilon)/(csr_matrix((denom + temp_pos).todense() + epsilon)))\n",
    "    W = ((W + W.T)/2)\n",
    "    #W = W.toarray()\n",
    "    Deg1 = sparse.diags(np.squeeze(np.asarray(W.sum(axis = 0)))).tocsr()\n",
    "    #W = csr_matrix(W)\n",
    "    #Deg1 = csr_matrix(Deg1)\n",
    "    return (Deg1, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870ed555-a73e-4172-b5f2-e58a680a37d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cupy.sparse import csr_matrix, kron\n",
    "from cupy.sparse import identity\n",
    "import scipy.sparse as sp\n",
    "def ADGNTD_stochastic_cp(Tens1, W_prior, r = 10, iter_steps = [1000, 2000, 3000],\n",
    "                      batchsize = [[20, 100, 20], [40,100,40], [60,100,60]], \n",
    "                      hy1=1, hy2=1, mu=0.1, factorization1=1000, max_iter = 6000,\n",
    "                      prin=50, A = None, B = None, C = None, W = None, delta = None ):\n",
    "    Tens1 = cp.asarray(Tens1)\n",
    "    W_prior = csr_matrix(W_prior)\n",
    "    def Khatri_Rao_Product(A1, B1):\n",
    "        result_list = [i * A1.shape[1] + i for i in range(B1.shape[1])]\n",
    "        temp = csr_matrix(kron(A1, B1))\n",
    "        temp = temp[:,result_list ]\n",
    "        return(temp)\n",
    "\n",
    "    def unfolding_3D(Tens, unfol_dim, other_dim_seq ):\n",
    "        X = Tens.transpose(unfol_dim, other_dim_seq[0], other_dim_seq[1]).reshape(Tens.shape[unfol_dim], Tens.shape[other_dim_seq[0]] * Tens.shape[other_dim_seq[1]])\n",
    "        return (X)\n",
    "\n",
    "\n",
    "    def calculate_smoothed_weights(mat):\n",
    "        identity_matrix = np.identity(mat.shape[0])\n",
    "        W_smooth = -pd.DataFrame(identity_matrix).rolling(2, axis=1).sum().replace(np.nan, 0)\n",
    "        W_smooth[0] = -pd.DataFrame(identity_matrix)[0]\n",
    "        W_smooth = np.array(W_smooth + 2 * pd.DataFrame(identity_matrix))\n",
    "        W_smooth_pos = (np.abs(W_smooth) + W_smooth) / 2\n",
    "        W_smooth_neg = (np.abs(W_smooth) - W_smooth) / 2\n",
    "        neum_term_B = cp.asarray(W_smooth_neg.T.dot(W_smooth_neg))\n",
    "        denom_term_B = cp.asarray(W_smooth_pos.T.dot(W_smooth_pos))\n",
    "        return  (csr_matrix(neum_term_B), csr_matrix(denom_term_B))\n",
    "\n",
    "    def vec_to_Mat(vec, shape):\n",
    "        x = shape[0]\n",
    "        y = shape[1]\n",
    "        Mat = vec.reshape(y,x).T\n",
    "        return (Mat)\n",
    "    \n",
    "    def derivative_dynamic_graph_B_W(A, B, W):\n",
    "        scipy_csr_identity = identity(W.shape[0], format='csr')\n",
    "        I_dash = cp.sparse.csr_matrix(scipy_csr_identity)\n",
    "        In = csr_matrix(cp.identity(A.shape[1]))\n",
    "        Ip = csr_matrix(cp.identity(B.shape[0]))\n",
    "        Xi_rep = kron(Khatri_Rao_Product(In, A), Ip)\n",
    "        kron_product = kron(In.T , W)\n",
    "        Xi = Xi_rep.T.dot(kron_product).dot(Xi_rep)\n",
    "        derivative_B = (Xi + Xi.T).dot(vect(B))\n",
    "        derivative_B_mat = vec_to_Mat(derivative_B, B.shape)\n",
    "        return(csr_matrix(derivative_B_mat))\n",
    "    \n",
    "    def derivative_dynamic_graph_B_D(A, B, Deg):\n",
    "        In = csr_matrix(cp.identity(A.shape[1]))\n",
    "        Ip = csr_matrix(cp.identity(B.shape[0]))\n",
    "        Xi_rep = kron(Khatri_Rao_Product(In, A), Ip)\n",
    "        Xi = Xi_rep.T.dot(kron(In.T , Deg)).dot(Xi_rep)\n",
    "        derivative_B = (Xi + Xi.T).dot(vect(B))\n",
    "        derivative_B_mat = vec_to_Mat(derivative_B, B.shape)\n",
    "        return(csr_matrix(derivative_B_mat))\n",
    "    \n",
    "    def derivative_dynamic_graph_A_W(A, B, W):\n",
    "        In = csr_matrix(cp.identity(A.shape[1]))\n",
    "        Ip = csr_matrix(cp.identity(B.shape[0]))\n",
    "        Imn = identity(A.shape[0] * A.shape[1], format='csr')\n",
    "        \n",
    "        ones = csr_matrix(cp.ones((1, A.shape[0])))\n",
    "        #print(type(B), type(Imn), type(In), type(ones))\n",
    "        #tensor_product(Imn, (B.dot(kron(In, ones))))\n",
    "        Eta_rep = csr_matrix(Khatri_Rao_Product(Imn, (B.dot(kron(In, ones)))))\n",
    "        Eta = Eta_rep.T.dot(kron(In.T, W)).dot(Eta_rep)\n",
    "        derivative_A = (Eta + Eta.T).dot(vect(A))\n",
    "        derivative_A_mat = vec_to_Mat(derivative_A, A.shape)\n",
    "        return(csr_matrix(derivative_A_mat))\n",
    "    \n",
    "    def derivative_dynamic_graph_A_D(A, B, Deg):\n",
    "        In = csr_matrix(cp.identity(A.shape[1]))\n",
    "        Ip = csr_matrix(cp.identity(B.shape[0]))\n",
    "        Imn = csr_matrix(cp.identity(A.shape[0] * A.shape[1]))\n",
    "        ones = csr_matrix(cp.ones((1, A.shape[0])))\n",
    "        Eta_rep = csr_matrix(Khatri_Rao_Product(Imn, (B.dot(kron(In, ones)))))\n",
    "        Eta = Eta_rep.T.dot(kron(In.T, Deg)).dot(Eta_rep)\n",
    "        derivative_A = (Eta + Eta.T).dot(vect(A))\n",
    "        derivative_A_mat = vec_to_Mat(derivative_A, A.shape)\n",
    "        return(csr_matrix(derivative_A_mat))\n",
    "    def calculate_rmse(y_true, y_pred):\n",
    "        squared_diff = (y_true - y_pred) ** 2\n",
    "        mean_squared_diff = cp.mean(squared_diff)\n",
    "        rmse = cp.sqrt(mean_squared_diff)\n",
    "        return rmse.item()\n",
    "    T3 = csr_matrix(unfolding_3D(Tens1, unfol_dim = 2, other_dim_seq = [0,1] ))\n",
    "    plot = []\n",
    "    try:\n",
    "        if (A is None) | (B is None)|  (C is None):\n",
    "            A = csr_matrix(cp.random.rand(Tens1.shape[0],r))\n",
    "            B = csr_matrix(cp.random.rand(Tens1.shape[1],r))\n",
    "            C = csr_matrix(cp.random.rand(Tens1.shape[2],r))\n",
    "        if (W is None):\n",
    "            W = W_prior.copy()\n",
    "            delta = W*.5\n",
    "        if delta is None:\n",
    "            delta = W*.5\n",
    "        A_list = list(range(A.shape[0]))\n",
    "        B_list = list(range(B.shape[0]))\n",
    "        C_list = list(range(C.shape[0]))\n",
    "        neum_term_B, denom_term_B = calculate_smoothed_weights(B)\n",
    "        start = 0\n",
    "        for indomie in range(max_iter):\n",
    "            try:\n",
    "                change_iter = iter_steps[start]\n",
    "            except:\n",
    "                change_iter = 100000000\n",
    "            if indomie >= change_iter:\n",
    "                start = start+1\n",
    "                #print('yes')\n",
    "            if indomie <= change_iter:\n",
    "                try:\n",
    "                    batchsize_selected = batchsize [start]\n",
    "                except:\n",
    "                    pass\n",
    "            #print(batchsize_selected)\n",
    "            A_Batch = int(batchsize_selected[0] / 100 * Tens1.shape[0] )\n",
    "            B_Batch = int(batchsize_selected[0] / 100 * Tens1.shape[1] )\n",
    "            #print(B_Batch)\n",
    "            C_Batch = int(batchsize_selected[2] / 100 * Tens1.shape[2] )\n",
    "            A_int = random.randrange(A.shape[0])\n",
    "            B_int = random.randrange(B.shape[0])\n",
    "            C_int = random.randrange(C.shape[0])\n",
    "            A_Sampling = random.sample(A_list, A_Batch)\n",
    "            B_Sampling = random.sample(B_list, B_Batch)\n",
    "            C_Sampling = random.sample(C_list, C_Batch)\n",
    "            A_Sampled = csr_matrix(A[A_Sampling, :])\n",
    "            B_Sampled = csr_matrix(B[B_Sampling, :])\n",
    "            C_Sampled = csr_matrix(C[C_Sampling, :])\n",
    "            Tens_sample = Tens1[A_Sampling, :, :][:, B_Sampling, :][:, :, C_Sampling]\n",
    "            #print(Tens_sample.shape)\n",
    "            T1_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=0, other_dim_seq=[1, 2]))\n",
    "            T2_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=1, other_dim_seq=[2, 0]))\n",
    "            T3_sampled = csr_matrix(unfolding_3D(Tens_sample, unfol_dim=2, other_dim_seq=[0, 1]))\n",
    "            # Loop through B_Sampling indices and create w_list_B\n",
    "            for index, j in enumerate(B_Sampling):\n",
    "                if index == 0:\n",
    "                    w_list_B = list(range(j * A.shape[0], (j + 1) * A.shape[0]))\n",
    "                if index > 0:\n",
    "                    w_list_B += list(range(j * A.shape[0], (j + 1) * A.shape[0]))\n",
    "            \n",
    "            # Loop through B indices and create w_list_A\n",
    "            for i in range(0, B.shape[0]):\n",
    "                if i == 0:\n",
    "                    w_list_A = list(np.array(A_Sampling) + i * A.shape[0])\n",
    "                if i > 0:\n",
    "                    w_list_A += list(np.array(A_Sampling) + i * A.shape[0])\n",
    "            #print(w_list_A, type(w_list_A), w_list_B, type(w_list_B))\n",
    "            # Find common indices between w_list_A and w_list_B\n",
    "            w_list = list(set(w_list_A) & set(w_list_B))\n",
    "            # Sample submatrix W_sampled from W using w_list indices\n",
    "            W_sampled = W[w_list, :][:, w_list]\n",
    "            #print(W_sampled.shape)\n",
    "            # Calculate degree matrix for sampled nodes\n",
    "            Deg_sampled = csr_matrix(cp.diag(cp.sum(W_sampled.toarray(), axis=1).ravel()))\n",
    "            # Sample submatrix W_prior_sampled from W_prior using w_list indices\n",
    "            W_prior_sampled = W_prior[w_list, :][:, w_list]\n",
    "            # Sample submatrix delta_sampled from delta using w_list indices\n",
    "            delta_sampled = delta[w_list, :][:, w_list]\n",
    "            # Create matrix V using Khatri-Rao product of B_Sampled and C_Sampled\n",
    "            V = csr_matrix(Khatri_Rao_Product(B_Sampled, C_Sampled))\n",
    "            # Update A_Sampled using optimization step\n",
    "            #print(type(V), type(T1_sampled))\n",
    "            A_num = A_Sampled.multiply(T1_sampled.dot(V) + hy1 * derivative_dynamic_graph_A_W(A_Sampled, B_Sampled, W_sampled))\n",
    "            A_denom = A_Sampled.dot(V.T).dot(V) + hy2 * A_Sampled + hy1 * derivative_dynamic_graph_A_D(A_Sampled, B_Sampled, Deg_sampled)\n",
    "            A_num.data += 0.000000001\n",
    "            A_denom.data += 0.000000001\n",
    "            A_Sampled = csr_matrix(A_num / A_denom)\n",
    "            # Update rows of A using A_Sampling indices\n",
    "            A[A_Sampling, :] = A_Sampled\n",
    "            # Recalculate matrix V using Khatri-Rao product of C_Sampled and A_Sampled\n",
    "            V = csr_matrix(Khatri_Rao_Product(C_Sampled, A_Sampled))\n",
    "            # Update B_Sampled using optimization step\n",
    "            #print(T2_sampled.shape, V.shape, type(T2_sampled), type(V), neum_term_B.shape, type(neum_term_B))\n",
    "            neum_term_B, denom_term_B = calculate_smoothed_weights(B)\n",
    "            neum_term_B = neum_term_B[B_Sampling, :][:, B_Sampling]\n",
    "            denom_term_B = denom_term_B[B_Sampling, :][:, B_Sampling]\n",
    "            B_num = B_Sampled.multiply(csr_matrix(T2_sampled.dot(V)) + 5 * (neum_term_B.dot(B_Sampled)) + hy1 * derivative_dynamic_graph_B_W(A_Sampled, B_Sampled, W_sampled))\n",
    "            B_num.data += 0.000000001\n",
    "            B_denom = (B_Sampled.dot(V.T).dot(V) + hy2 * B_Sampled + 5 * (denom_term_B.dot(B_Sampled)) + hy1 * derivative_dynamic_graph_B_D(A_Sampled, B_Sampled, Deg_sampled))\n",
    "            B_denom.data += 0.000000001\n",
    "            B_Sampled = csr_matrix(B_num / B_denom)\n",
    "            # Update rows of B using B_Sampling indices\n",
    "            B[B_Sampling, :] = B_Sampled\n",
    "            # Recalculate matrix V using Khatri-Rao product of A_Sampled and B_Sampled\n",
    "            V = csr_matrix(Khatri_Rao_Product(A_Sampled, B_Sampled))\n",
    "            # Update C_Sampled using optimization step\n",
    "            C_num = C_Sampled.multiply(T3_sampled.dot(V))\n",
    "            C_denom = (C_Sampled.dot(V.T).dot(V) + hy2 * C_Sampled)\n",
    "            C_num.data += 0.000000001\n",
    "            C_denom.data += 0.000000001\n",
    "            C_Sampled = C_num/ C_denom\n",
    "            # Update rows of C using C_Sampling indices\n",
    "            C[C_Sampling, :] = C_Sampled\n",
    "            # Estimate matrix EstimatedT4 using calculated matrices\n",
    "            EstimatedT4 = C.dot(Khatri_Rao_Product(A, B).T)\n",
    "            # Update delta_sampled with mu term\n",
    "            \n",
    "            feature_Matrix = csr_matrix(Khatri_Rao_Product(A_Sampled, B_Sampled))\n",
    "            #print((Lambda_priorW * W_prior).shape)\n",
    "            #print((Lambda_adaptive * .5* feature_Matrix.dot(feature_Matrix.T)).shape) \n",
    "            #print(Lambda_priorW * W_prior + Lambda_adaptive * .5* feature_Matrix.dot(feature_Matrix.T)) \n",
    "            Deg1, W1 = adaptive_Adjacency_aug_cp(W_sampled, W_prior_sampled, feature_Matrix, mu, delta_sampled, Lambda_adaptive, Lambda_priorW , epsilon )\n",
    "            #print(C.shape, A.shape, B.shape)\n",
    "            W[w_list, :][:, w_list] = W1\n",
    "            Deg = cp.sparse.diags(cp.squeeze(cp.asarray(W.sum(axis = 0)))).tocsr()\n",
    "            if indomie%prin == 0:\n",
    "                try:\n",
    "                    factorization1 =  min(factorization, factorization1)\n",
    "                except:\n",
    "                    pass\n",
    "                factorization = calculate_rmse(T3.toarray(), EstimatedT4.toarray())\n",
    "                plot.append([indomie, factorization])\n",
    "                abcd = pd.DataFrame(plot, columns = ['iteration', 'RMSE'])\n",
    "            if indomie%prin == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(\".............................................\")\n",
    "                print('iteration:                       ',indomie)\n",
    "                print('rmse factorization :             ', factorization )\n",
    "                try:\n",
    "                    print('rmse factorization min:          ', min(factorization, factorization1))\n",
    "                    print('batchsize_selected:          ', batchsize_selected)\n",
    "                    #batchsize_selected\n",
    "                except:\n",
    "                    pass\n",
    "                print('.............................................')\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard interruption detected. Returning...\")\n",
    "        return(A, B, C, W, delta)\n",
    "        \n",
    "    return(A, B, C, W, delta)\n",
    "def adaptive_Adjacency_aug_cp(W, W_prior, feature_Matrix, mu, delta, Lambda_adaptive, Lambda_priorW , epsilon ):\n",
    "    neum = csr_matrix(Lambda_priorW * W_prior + Lambda_adaptive * .5* feature_Matrix.dot(feature_Matrix.T)) #OK \n",
    "    One_n = csr_matrix(cp.ones(W.shape[0]).reshape(W.shape[0], 1))\n",
    "    Identity_r = csr_matrix(cp.identity(feature_Matrix.shape[1]))\n",
    "    Identity_n = csr_matrix(cp.identity(W.shape[0]))\n",
    "    Third_term = csr_matrix((feature_Matrix.dot(Identity_r).dot(feature_Matrix.T).multiply(Identity_n) ).dot(One_n).dot(One_n.T)) \n",
    "    denom =  Lambda_adaptive * .5* Third_term + Lambda_priorW * W #+ .5* cp.identity(W.shape[0]) \n",
    "    temp = mu * (W-W.T) + delta - delta.T\n",
    "    temp_pos = (abs(temp) + temp)/2\n",
    "    temp_neg = (abs(temp) - temp)/2\n",
    "    W = W.multiply(csr_matrix((neum  + temp_neg).todense() + epsilon)/(csr_matrix((denom + temp_pos).todense() + epsilon)))\n",
    "    W = ((W + W.T)/2)\n",
    "    #W = W.toarray()\n",
    "    Deg1 = csr_matrix(cp.diag(cp.sum(W.toarray(), axis=1).ravel()))\n",
    "    #Deg1 = sparse.diags(cp.squeeze(cp.asarray(W.sum(axis = 0)))).tocsr()\n",
    "    #W = csr_matrix(W)\n",
    "    #Deg1 = csr_matrix(Deg1)\n",
    "    return (Deg1, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a6f500-ff3a-4f1c-ac3d-2902314cc2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import sparse\n",
    "# Set up data directory\n",
    "name = 'Logan'\n",
    "data_directory = r'\\\\hpc-fs.qut.edu.au\\n10680535\\Paper_5\\Datasets'\n",
    "\n",
    "# Load data\n",
    "Tens = np.load(os.path.join(data_directory, f'Train_{name}_3D_data.npy'))\n",
    "Test_Tens = np.load(os.path.join(data_directory, f'Test_{name}_3D_data.npy'))\n",
    "test_dataset = pd.read_csv(os.path.join(data_directory, f'test_{name}_data.csv'), index_col=[0, 1], header=[0])\n",
    "Val_Tens = np.load(os.path.join(data_directory, f'Val_{name}_3D_data.npy'))\n",
    "val_dataset = pd.read_csv(os.path.join(data_directory, f'Val_{name}_data.csv'), index_col=[0, 1], header=[0])\n",
    "ind = pd.read_csv(os.path.join(data_directory, 'date_time_train.csv'), index_col=[0, 1])\n",
    "stl_clm = pd.read_csv(os.path.join(data_directory, 'section_names.csv'), index_col=0)\n",
    "train_data_shubham = pd.read_csv(os.path.join(data_directory, f'Train_{name}_data.csv'), index_col=[0, 1], header=[0])\n",
    "W = sparse.load_npz(os.path.join(data_directory, f'Dynamic_Adjacency_{name}.npz'))\n",
    "MWY_Sections = pd.read_csv(os.path.join(data_directory, 'MWY_Sections.csv'))\n",
    "\n",
    "# Extract section IDs\n",
    "section_ids = train_data_shubham.columns.to_list()\n",
    "serial_numbers = [test_dataset.columns.get_loc(section_id) for section_id in section_ids]\n",
    "\n",
    "# Manipulate data based on section IDs\n",
    "Tens = Tens[serial_numbers, :, :]\n",
    "Test_Tens = Test_Tens[serial_numbers, :, :]\n",
    "Val_Tens = Val_Tens[serial_numbers, :, :]\n",
    "stl_clm = stl_clm.iloc[serial_numbers]\n",
    "train_data_shubham = train_data_shubham.T.iloc[serial_numbers].T\n",
    "test_dataset = test_dataset.T.iloc[serial_numbers].T\n",
    "val_dataset = val_dataset.T.iloc[serial_numbers].T\n",
    "\n",
    "# Additional data manipulations\n",
    "stl_clm.index = stl_clm.index.astype('str')\n",
    "test_dataset = test_dataset[stl_clm.index].T\n",
    "test_data_prior = test_dataset.copy(deep=True)\n",
    "val_dataset = val_dataset[stl_clm.index].T\n",
    "val_data_prior = val_dataset.copy(deep=True)\n",
    "test_dataset_col = test_dataset.columns\n",
    "val_dataset_col = val_dataset.columns\n",
    "train_data_shubham = train_data_shubham[test_data_prior.index.astype(str)]\n",
    "train_data_shubham_prior = train_data_shubham.T\n",
    "\n",
    "# Update serial numbers for W\n",
    "serial_numbers_W = serial_numbers.copy()\n",
    "for i in range(1, 96):\n",
    "    for j in serial_numbers:\n",
    "        serial_numbers_W.append(i * 476 + j)\n",
    "\n",
    "# Update adjacency matrix W\n",
    "W = coo_matrix(W.toarray()[serial_numbers_W].T[serial_numbers_W].T)\n",
    "W = coo_matrix(W)\n",
    "W_dense = W.toarray()\n",
    "W = (W + W.T) / 2\n",
    "W.setdiag(0, k=0)\n",
    "Deg = sparse.diags(np.squeeze(np.asarray(W.sum(axis=0)))).tocsr()\n",
    "\n",
    "# File path for complete data\n",
    "file_path = os.path.join(data_directory, 'Complete_Logan_3D_data.npy')\n",
    "Complete_Tens = np.load(file_path)\n",
    "Complete_Tens = Complete_Tens[serial_numbers, :, :]\n",
    "\n",
    "# Additional data transformation\n",
    "Tens1 = Tens.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896893ad-f350-4335-9445-bea63bbf1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rank = 20\n",
    "Lambda_adaptive = 0.0001\n",
    "Lambda_priorW = 0.01\n",
    "epsilon   = 0.0000001\n",
    "hy1=.001\n",
    "A_L, B_L, C_L, W, delta = ADGNTD_stochastic_cp(Tens1, W, r = r, iter_steps = [6000],\n",
    "                      batchsize = [[20, 100, 20]], \n",
    "                      hy1= hy1, hy2=.0001, mu=0.1, factorization1=1000,\n",
    "                      prin=5, A = None, B = None, C = None, W = None, delta = None )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c056fe4d-df05-42ad-a7bd-dd42020a0095",
   "metadata": {},
   "source": [
    "11. Test code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f853c7-5250-4ed3-ac7e-6976d96c0748",
   "metadata": {},
   "source": [
    "ADGNTD Entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573c9d99-3fcc-4a32-9514-171aa90e6d8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A_L' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m A \u001b[38;5;241m=\u001b[39m  \u001b[43mA_L\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m      2\u001b[0m B \u001b[38;5;241m=\u001b[39m  C_L\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m      3\u001b[0m C \u001b[38;5;241m=\u001b[39m  B_L\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A_L' is not defined"
     ]
    }
   ],
   "source": [
    "A =  A_L.copy().toarray()\n",
    "B =  C_L.copy().toarray()\n",
    "C =  B_L.copy().toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67808901-de8b-4856-bbfc-b1524702c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "np.save('A20.npy', A)\n",
    "np.save('B20.npy', B)\n",
    "np.save('C20.npy', C)\n",
    "scipy.sparse.save_npz('W_s.npz', W)\n",
    "scipy.sparse.save_npz('delta_s.npz', delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32352de-a7f2-43e7-832d-60854d88e08a",
   "metadata": {},
   "source": [
    "### Rank = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812726f0-2178-48b4-8d94-2443927d57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rank = 10\n",
    "Lambda_adaptive = 0.0001\n",
    "Lambda_priorW = 0.01\n",
    "epsilon   = 0.0000001\n",
    "hy1=.001\n",
    "A_L, B_L, C_L, W, delta = ADGNTD_stochastic_cp(Tens1, W, r = rank, iter_steps = [6000],\n",
    "                      batchsize = [[20, 100, 20]], \n",
    "                      hy1= hy1, hy2=.0001, mu=0.1, factorization1=1000,\n",
    "                      prin=5, A = None, B = None, C = None, W = None, delta = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238b1610-e989-4be7-9a0c-e997edd6bd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea78ee-5cc8-4f7f-bdd1-0cc0044d94ab",
   "metadata": {},
   "source": [
    "# import cupy\n",
    "print(\"TensorFlow version:\", cupy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbc1e1-5982-41e5-a083-e608399d4485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
